{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Explainability (Assignment 9)\n",
    "\n",
    "## Student: Rodolfo Lerma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will use `LIME` library to perform local explanations using surrogate modelsto explain the results of Random Forest Classifier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BOOK for this](https://github.com/ajaymache/machine-learning-yearning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import plotly\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 7]\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "# import lime\n",
    "# import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('./music.xls')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe contains 35 features/columns and 10,000 datapoints/rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from `artist.id` & `song.id` all the other columns are either *float64* or *int64*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.isnull.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1: Create the target of popular artists where artist familiarity is greater than 0.8 and artist hotttness is greater than 0.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['class'] = np.where((df_data['artist.familiarity'] > 0.8) & (df_data['artist.hotttnesss'] > 0.6), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Grouby on class and count artist.id\n",
    "artists = df_data.groupby(['class']).count()['artist.id']\n",
    "artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.catplot(x=\"class\", kind=\"count\", palette=\"ch:.1\", data=df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the distribution of the `class` column, we can see there is a class imbalance present. For this reason I will test 2 models, one with the class imbalance present and another without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_plot(df,a):\n",
    "    df[a].hist(figsize = (5,3))\n",
    "    plt.xlabel(a, fontsize = 15)\n",
    "    plt.ylabel('Frequency',fontsize = 15)\n",
    "    plt.tick_params(axis=\"x\", labelsize=10)\n",
    "    plt.tick_params(axis=\"y\", labelsize=10)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_keep = ['song.bars_confidence', \n",
    "             'song.bars_start', \n",
    "             'song.beats_confidence', \n",
    "             'song.beats_start', \n",
    "             'song.duration', \n",
    "             'song.end_of_fade_in', \n",
    "             'song.hotttnesss', \n",
    "             'song.key_confidence', \n",
    "             'song.loudness', \n",
    "             'song.mode', \n",
    "             'song.mode_confidence', \n",
    "             'song.start_of_fade_out', \n",
    "             'song.tatums_confidence', \n",
    "             'song.tatums_start', \n",
    "             'song.tempo', \n",
    "             'song.time_signature', \n",
    "             'song.time_signature_confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[vars_keep].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in vars_keep:\n",
    "    hist_plot(df_data, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2: Train a Random Forest Classifier with 100 estimators considering these variables:\n",
    "* vars_keep = ['song.bars_confidence', 'song.bars_start', 'song.beats_confidence', 'song.beats_start', 'song.duration', 'song.end_of_fade_in', 'song.hotttnesss', 'song.key_confidence', 'song.loudness', 'song.mode', 'song.mode_confidence', 'song.start_of_fade_out', 'song.tatums_confidence', 'song.tatums_start', 'song.tempo', 'song.time_signature', 'song.time_signature_confidence']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data[vars_keep]\n",
    "y = df_data['class']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "print('Training set size - X_train: {} '.format(X_train.shape))\n",
    "print('Training set size - X_test: {} '.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier n_estimates =100, oob_score = True, random_state = 123456\n",
    "rf = RandomForestClassifier(n_estimators = 100, oob_score = True, random_state = 123456)\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_values(X_test, y_test, trained_model):\n",
    "    \n",
    "    from sklearn import preprocessing, metrics\n",
    "    from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "    \n",
    "    y_pred = trained_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    probs = trained_model.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, preds)\n",
    "    return (fpr, tpr, accuracy, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_curve(fpr,tpr,roc_auc):\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, rf_acc, rf_roc_auc = performance_values(X_test, Y_test, rf)\n",
    "print(\"Accuracy: {}\".format(rf_acc))\n",
    "print(\"AUC: {}\".format(rf_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_curve(fpr,tpr,rf_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1: Initializing the LIME explainer. You need to include the following conditions - feature_names, class_names, verbose, discretize_continuous, and mode. It is important to note that when you tune class_name that the order is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train, \n",
    "                                                   feature_names = vars_keep, \n",
    "                                                   class_names = [0,1],\n",
    "                                                   verbose = True,\n",
    "                                                   mode = \"classification\",\n",
    "                                                   discretize_continuous=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, you need to visit the [documentation](https://github.com/marcotcr/lime) for `LIME` and find out how you can pass an instance to get a local explanation and produce some visualizations. Since we are using `LimeTabularExplainer`, you can focus on that in the documentation (example notebooks are provided)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2: Choose an instance from the test data, and obtain explanations for it. The explanations should include no more than 5 features (the top 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_num = np.random.randint(0, X_test.shape[0])\n",
    "\n",
    "local_exp = explainer.explain_instance(X_test.iloc[instance_num], rf.predict_proba, num_features = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.3: Produce a feature importance plot for the explanation. HINT: `LIME` has a method for this. You only need to call it. <span style=\"color:red\" float:right>; # you need the semi-colon otherwise two dublicate plots are produced</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = local_exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show local_exp data frame as a list\n",
    "local_exp.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quesiont 3: Call the `show_in_notebook` method to show a summary of the explanation. Set show_table = True, show_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "local_exp.show_in_notebook(show_table=True, show_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Interpret the results shown by calling `show_in_notebook`. Confirm that the predicted probability shown on the left matches the predicted probability we get by calling the model directly on the instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the input values for this particular entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[instance_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = rf.predict_proba(X_test)\n",
    "example[instance_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rf.predict(X_test)\n",
    "prediction[instance_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the probabilities for both classes are the same as the ones we saw from the LIME plots above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Bonus] Question 5: Repeat the above steps with a Support Vector Machine Classifier. What conclusions to you draw about model explainablity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"C\": [0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "              \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "              \"probability\": [True]}\n",
    "\n",
    "svm_base = SVC()\n",
    "\n",
    "svm_grid = GridSearchCV(estimator = svm_base, param_grid = parameters,\n",
    "                        cv = 10, verbose = 2, n_jobs = -1)\n",
    "\n",
    "svm_grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters Best Parameters\n",
    "best_params = svm_grid.best_params_\n",
    "print(\"Best Hyperparameters: {}\".format(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, svm_acc, svm_roc_auc = performance_values(X_test, Y_test, svm_grid)\n",
    "print(\"Accuracy: {}\".format(svm_acc))\n",
    "print(\"AUC: {}\".format(svm_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_curve(fpr,tpr,svm_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_svm = lime.lime_tabular.LimeTabularExplainer(X_train, \n",
    "                                                   feature_names = vars_keep, \n",
    "                                                   class_names = [0,1],\n",
    "                                                   verbose = True,\n",
    "                                                   mode = \"classification\",\n",
    "                                                   discretize_continuous=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_exp_svm = explainer_svm.explain_instance(X_test.iloc[instance_num], svm.predict_proba, num_features = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_svm = local_exp_svm.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_exp_svm.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_exp_svm.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Create a new text cell in your Notebook: Complete a 50-100 word summary (or short description of your thinking in applying this week's learning to the solution) of your experience in this assignment. Include: \n",
    "- What was your incoming experience with this model, if any? \n",
    "- what steps you took, what obstacles you encountered?\n",
    "- How you link this exercise to real-world, machine learning problem-solving?\n",
    "- What steps were missing? \n",
    "- What else do you need to learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in class the topic of Explainability & Interpretability are taking more and more importance as we see the use & impact of Machine Learning more and more in our daily life. In my experience working with thermodynamic data of commercial engines to create Machine Learning Models to predict behavior and/or potential safety issues (such as engine failures) it was always preferred a simpler model that offer better Explainability & Interpretability, even if that meant lower performance values. This, because having a clear understanding of the variables at play and how they interact with each other to produce the final prediction was more important that the prediction itself, especially since almost all the issues were related to safety.\n",
    "\n",
    "This assignment was really interesting as I have never worked with LIME to help to explain a complex model that otherwise would be very difficult (if not impossible) to clearly explain the reason on why is predicting a particular result. \n",
    "\n",
    "[Article](https://towardsdatascience.com/interpretability-in-machine-learning-70c30694a05f)\n",
    "\n",
    "**Accounting for the context of the problem.**\n",
    "\n",
    "In most problems, you are working with a dataset that is only a rough representation of the problem you are trying to solve and a machine learning model can typically not capture the full complexity of the real-life task. An interpretable model helps you to understand and account for the factors that are (not) included in the model and account for the context of the problem when taking actions based on model predictions.\n",
    "\n",
    "**Improving generalisation and performance.**\n",
    "\n",
    "A high interpretability typically leads to a model that generalises better. Interpretability is not about understanding every single detail of the model for all of the data points. The combination of solid data, model and problem understanding is necessary to have a solution that performs better.\n",
    "\n",
    "**Ethical and legal reasons.**\n",
    "\n",
    "In industries like finance and healthcare it is essential to audit the decision process and ensure it is e.g. not discriminatory or violating any laws. With the rise of data and privacy protection regulation like GDPR, interpretability becomes even more essential. In addition, in medical applications or self-driving cars, a single incorrect prediction can have a significant impact and being able to ‘verify’ the model is critical. Therefore the system should be able to explain how it reached a given recommendation.\n",
    "\n",
    "\n",
    "LIME is a great tool to explain what machine learning classifiers (or models) are doing. It is model-agnostic, leverages simple and understandable idea’s and does not require a lot of effort to run. As always, even when using LIME, it is still important to correctly interpret the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
